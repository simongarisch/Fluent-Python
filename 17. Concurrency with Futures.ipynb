{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency with Futures\n",
    "This chapter focuses on the concurrent.futures library introduced in Python 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Sequential Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 flags downloaded in 18.58s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP MX PH VN ET EG DE IR TR CD FR').split()\n",
    "BASE_URL = 'http://flupy.org/data/flags'\n",
    "DEST_DIR = 'downloads/'\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "def show(text):\n",
    "    print(text, end=' ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_many(cc_list):\n",
    "    for cc in sorted(cc_list):\n",
    "        image = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "def create_downloads_folder():\n",
    "    if not os.path.isdir(\"downloads\"):\n",
    "        os.mkdir(\"downloads\")\n",
    "\n",
    "def main(download_many):\n",
    "    create_downloads_folder()\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This serves as a baseline for comparing the other scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with concurrent.futures\n",
    "The main features of the concurrent.futures package are the ThreadPoolExecutor and ProcessPoolExecutor classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD ID DEEGFR CN JPRUBR TR  MX INVNNG ET    IRPKUSCD PH      \n",
      "20 flags downloaded in 1.42s\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "def download_one(cc):\n",
    "    image = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    return len(list(res))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a substantial improvement in download speed. The easiest way to implement the downloads concurrently, using the ThreadPoolExecutor.map method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where Are the Futures?\n",
    "As of Python 3.4, there are two classes named Future in the standard library: concurrent.futures.Future and asyncio.Future. They serve the same purpose: an instance of either Future class represents a deferred computation that may or may not have\n",
    "completed. This is similar to the Deferred class in Twisted, the Future class in Tornado, and Promise objects in various JavaScript libraries.\n",
    "\n",
    "Strictly speaking, none of the concurrent scripts we tested so far can perform downloads in parallel. The concurrent.futures examples are limited by the GIL, and the flags_asyncio.py is single-threaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking I/O and the GIL\n",
    "The CPython interpreter is not thread-safe internally, so it has a Global Interpreter Lock (GIL), which allows only one thread at a time to execute Python bytecodes. That’s why a single Python process usually cannot use multiple CPU cores at the same time.\n",
    "\n",
    "However, all standard library functions that perform blocking I/O release the GIL when waiting for a result from the OS. This means Python programs that are I/O bound can benefit from using threads at the Python level: while one Python thread is waiting for a response from the network, the blocked I/O function releases the GIL so another thread can run.\n",
    "\n",
    "That’s why David Beazley says: 'Python threads are great at doing nothing.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Processes with concurrent.futures\n",
    "Both ProcessPoolExecutor and ThreadPoolExecutor implement the generic Executor interface, so it’s very easy to switch from a thread-based to a process-based solution using concurrent.futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "input_list = range(20)\n",
    "\n",
    "\n",
    "def run_thread_pool(input_list):\n",
    "    workers = min(MAX_WORKERS, len(input_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(math.sqrt, input_list)\n",
    "    return res\n",
    "\n",
    "\n",
    "def run_process_pool(input_list):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(math.sqrt, input_list)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ms ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_thread_pool(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547 ms ± 136 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_process_pool(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is overhead is using different processes. The value of ProcessPoolExecutor is in CPU-intensive jobs. workers is an optional argument in ProcessPoolExecutor, and most of the time we don’t use it—the default is the number of CPUs returned by os.cpu_count(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Executor.map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:03:15] Script starting.\n",
      "[06:03:15] loiter(0): doing nothing for 0s...\n",
      "[06:03:15] loiter(0): done.\n",
      "[06:03:15] \tloiter(1): doing nothing for 1s...\n",
      "[06:03:15][06:03:15] \t\tloiter(2): doing nothing for 2s...\n",
      "[06:03:15] results: \t\t\tloiter(3): doing nothing for 3s...\n",
      " <generator object Executor.map.<locals>.result_iterator at 0x0000000004EBEC50>\n",
      "[06:03:15] Waiting for individual results:\n",
      "[06:03:15] result 0: 0\n",
      "[06:03:16] \tloiter(1): done.\n",
      "[06:03:16][06:03:16] \t\t\t\tloiter(4): doing nothing for 4s...\n",
      " result 1: 10\n",
      "[06:03:17] \t\tloiter(2): done.\n",
      "[06:03:17] result 2: 20\n",
      "[06:03:18] \t\t\tloiter(3): done.\n",
      "[06:03:18] result 3: 30\n",
      "[06:03:20] \t\t\t\tloiter(4): done.\n",
      "[06:03:20] result 4: 40\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args):\n",
    "    print(strftime('[%H:%M:%S]'), end=' ')\n",
    "    print(*args)\n",
    "\n",
    "def loiter(n):\n",
    "    msg = '{}loiter({}): doing nothing for {}s...'\n",
    "    display(msg.format('\\t'*n, n, n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done.'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n * 10\n",
    "\n",
    "def main():\n",
    "    display('Script starting.')\n",
    "    executor = futures.ThreadPoolExecutor(max_workers=3)\n",
    "    results = executor.map(loiter, range(5))\n",
    "    display('results:', results)\n",
    "    display('Waiting for individual results:')\n",
    "    for i, result in enumerate(results):\n",
    "        display('result {}: {}'.format(i, result))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will resume the flag download examples with new requirements that will force us to iterate over the results of futures.as_completed instead of using executor.map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloads with Progress Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:01<00:00, 86.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the docs of tqdm: Instantly make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable), and you’re done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling in the flags2 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_flag(base_url, cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "def download_one(cc, base_url, verbose=False):\n",
    "    try:\n",
    "        image = get_flag(base_url, cc)\n",
    "    except requests.exceptions.HTTPError as exc:\n",
    "        res = exc.response\n",
    "        if res.status_code == 404:\n",
    "            status = HTTPStatus.not_found\n",
    "            msg = 'not found'\n",
    "        else:\n",
    "            raise\n",
    "    else:\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "        status = HTTPStatus.ok\n",
    "        msg = 'OK'\n",
    "        if verbose:\n",
    "            print(cc, msg)\n",
    "        return Result(status, cc) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
