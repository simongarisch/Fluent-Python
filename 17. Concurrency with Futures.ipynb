{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency with Futures\n",
    "This chapter focuses on the concurrent.futures library introduced in Python 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Sequential Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN \n",
      "20 flags downloaded in 18.58s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP MX PH VN ET EG DE IR TR CD FR').split()\n",
    "BASE_URL = 'http://flupy.org/data/flags'\n",
    "DEST_DIR = 'downloads/'\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "def get_flag(cc):\n",
    "    url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower())\n",
    "    resp = requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "def show(text):\n",
    "    print(text, end=' ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def download_many(cc_list):\n",
    "    for cc in sorted(cc_list):\n",
    "        image = get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(image, cc.lower() + '.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "def create_downloads_folder():\n",
    "    if not os.path.isdir(\"downloads\"):\n",
    "        os.mkdir(\"downloads\")\n",
    "\n",
    "def main(download_many):\n",
    "    create_downloads_folder()\n",
    "    t0 = time.time()\n",
    "    count = download_many(POP20_CC)\n",
    "    elapsed = time.time() - t0\n",
    "    msg = '\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count, elapsed))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This serves as a baseline for comparing the other scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading with concurrent.futures\n",
    "The main features of the concurrent.futures package are the ThreadPoolExecutor and ProcessPoolExecutor classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD ID DEEGFR CN JPRUBR TR  MX INVNNG ET    IRPKUSCD PH      \n",
      "20 flags downloaded in 1.42s\n"
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "def download_one(cc):\n",
    "    image = get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image, cc.lower() + '.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers = min(MAX_WORKERS, len(cc_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(download_one, sorted(cc_list))\n",
    "    return len(list(res))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a substantial improvement in download speed. The easiest way to implement the downloads concurrently, using the ThreadPoolExecutor.map method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where Are the Futures?\n",
    "As of Python 3.4, there are two classes named Future in the standard library: concurrent.futures.Future and asyncio.Future. They serve the same purpose: an instance of either Future class represents a deferred computation that may or may not have\n",
    "completed. This is similar to the Deferred class in Twisted, the Future class in Tornado, and Promise objects in various JavaScript libraries.\n",
    "\n",
    "Strictly speaking, none of the concurrent scripts we tested so far can perform downloads in parallel. The concurrent.futures examples are limited by the GIL, and the flags_asyncio.py is single-threaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking I/O and the GIL\n",
    "The CPython interpreter is not thread-safe internally, so it has a Global Interpreter Lock (GIL), which allows only one thread at a time to execute Python bytecodes. That’s why a single Python process usually cannot use multiple CPU cores at the same time.\n",
    "\n",
    "However, all standard library functions that perform blocking I/O release the GIL when waiting for a result from the OS. This means Python programs that are I/O bound can benefit from using threads at the Python level: while one Python thread is waiting for a response from the network, the blocked I/O function releases the GIL so another thread can run.\n",
    "\n",
    "That’s why David Beazley says: 'Python threads are great at doing nothing.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching Processes with concurrent.futures\n",
    "Both ProcessPoolExecutor and ThreadPoolExecutor implement the generic Executor interface, so it’s very easy to switch from a thread-based to a process-based solution using concurrent.futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from concurrent import futures\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "input_list = range(20)\n",
    "\n",
    "\n",
    "def run_thread_pool(input_list):\n",
    "    workers = min(MAX_WORKERS, len(input_list))\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(math.sqrt, input_list)\n",
    "    return res\n",
    "\n",
    "\n",
    "def run_process_pool(input_list):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res = executor.map(math.sqrt, input_list)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ms ± 3.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_thread_pool(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547 ms ± 136 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_process_pool(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is overhead is using different processes. The value of ProcessPoolExecutor is in CPU-intensive jobs. workers is an optional argument in ProcessPoolExecutor, and most of the time we don’t use it—the default is the number of CPUs returned by os.cpu_count(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Executor.map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
